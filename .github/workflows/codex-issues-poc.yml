name: Codex Issue Bot (PoC)

on:
  issue_comment:
    types: [created]
  issues:
    types: [opened, edited]

permissions:
  contents: read
  issues: write

concurrency:
  group: codex-issue-${{ github.event.issue.number }}
  cancel-in-progress: false

jobs:
  codex:
    if: >
      github.actor == 'hewrin' &&
      github.event.sender.type != 'Bot' &&
      (
        (github.event_name == 'issue_comment' && startsWith(github.event.comment.body, '/codex')) ||
        (github.event_name == 'issues' && startsWith(github.event.issue.body, '/codex'))
      )

    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Build prompt + call OpenAI (with all issue comments)
        id: openai
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          EVENT_NAME: ${{ github.event_name }}
          ISSUE_TITLE: ${{ github.event.issue.title }}
          ISSUE_BODY: ${{ github.event.issue.body }}
          COMMENT_BODY: ${{ github.event.comment.body }}
          REPO: ${{ github.repository }}
          ISSUE_NUMBER: ${{ github.event.issue.number }}
          ACTOR: ${{ github.actor }}
        run: |
          set -euo pipefail

          # Determine where /codex came from
          if [ "$EVENT_NAME" = "issue_comment" ]; then
            SOURCE_TEXT="${COMMENT_BODY:-}"
          else
            SOURCE_TEXT="${ISSUE_BODY:-}"
          fi

          # Strip /codex prefix
          QUESTION="$(printf '%s' "$SOURCE_TEXT" | sed -e 's/^\/codex[[:space:]]*//')"
          if [ -z "$QUESTION" ]; then
            echo "No question after /codex" >&2
            exit 1
          fi

          # Cheap context: list model files (optional but helpful)
          MODEL_FILES="$(ls -1 app/models 2>/dev/null | head -n 200 || true)"

          # Pull ALL issue comments (paginate)
          # Output format: one block per comment with author + timestamp + body
          COMMENTS_JSON="$(gh api --paginate "repos/${REPO}/issues/${ISSUE_NUMBER}/comments")"

          # Turn comments JSON into a single plain-text transcript
          COMMENTS_TEXT="$(
            printf '%s' "$COMMENTS_JSON" | jq -r '
              sort_by(.created_at) |
              map(
                "-----\n" +
                (.user.login // "unknown") + " @ " + (.created_at // "unknown") + "\n" +
                (.body // "")
              ) | join("\n\n")
            '
          )"

          # Safety cap: conversations can get huge. We still fetch all comments,
          # but we truncate what we SEND to the model to avoid token blowups.
          # Increase/decrease as you like.
          MAX_CHARS=45000
          if [ "${#COMMENTS_TEXT}" -gt "$MAX_CHARS" ]; then
            COMMENTS_TEXT="(Truncated to last ${MAX_CHARS} chars of the issue comment thread)\n\n${COMMENTS_TEXT: -$MAX_CHARS}"
          fi

          SYSTEM_PROMPT="You are a GitHub Issue assistant."
          SYSTEM_PROMPT+=$'\nContinue the conversation using the full issue thread provided.'
          SYSTEM_PROMPT+=$'\nBe concise and practical.'
          SYSTEM_PROMPT+=$'\nIf you need more code context, ask for specific file paths.'

          USER_PROMPT="Repository: ${REPO}"
          USER_PROMPT+=$'\n\nEvent: '"${EVENT_NAME}"
          USER_PROMPT+=$'\n\nIssue title:\n'"${ISSUE_TITLE}"
          USER_PROMPT+=$'\n\nIssue body:\n'"${ISSUE_BODY:-"(empty)"}"
          USER_PROMPT+=$'\n\nAll issue comments (chronological):\n'"${COMMENTS_TEXT:-"(no comments found)"}"
          USER_PROMPT+=$'\n\nRails model files (app/models):\n'"${MODEL_FILES:-"(none found)"}"
          USER_PROMPT+=$'\n\nNew question from '"${ACTOR}"$':\n'"${QUESTION}"

          PAYLOAD="$(jq -n \
            --arg system "$SYSTEM_PROMPT" \
            --arg user "$USER_PROMPT" \
            '{
              model: "gpt-5.2-codex",
              reasoning: { effort: "low" },
              max_output_tokens: 800,
              input: [
                { role: "developer", content: $system },
                { role: "user", content: $user }
              ]
            }'
          )"

          RESPONSE_JSON="$(curl -sS https://api.openai.com/v1/responses \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $OPENAI_API_KEY" \
            -d "$PAYLOAD")"

          # Robust extraction of assistant text
          ANSWER="$(
            printf '%s' "$RESPONSE_JSON" | jq -r '
              .output_text
              // ([
                .output[]?
                | select(.type=="message")
                | .content[]?
                | select(.type=="output_text")
                | .text
              ] | join("\n"))
              // empty
            '
          )"

          if [ -z "$ANSWER" ]; then
            echo "No assistant text returned" >&2
            echo "$RESPONSE_JSON" >&2
            exit 1
          fi

          {
            echo "answer<<EOF"
            echo "$ANSWER"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      - name: Post reply as issue comment
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
          ISSUE_NUMBER: ${{ github.event.issue.number }}
          ANSWER: ${{ steps.openai.outputs.answer }}
        run: |
          set -euo pipefail
          BODY="**Codex reply:**"
          BODY+=$'\n\n'"${ANSWER}"
          BODY+=$'\n\nâ€”\nTriggered by `'"'/codex'"'`'
          gh api "repos/${REPO}/issues/${ISSUE_NUMBER}/comments" -f body="$BODY"
